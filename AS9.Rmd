---
title: "HW9"
author: "Bowen Zheng"
date: "11/13/2021"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


(a) Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.
```{r}
library(ISLR)
library(data.table)
set.seed(53)
train<-sample(dim(OJ)[1], 800)
train.OJ<-OJ[train,]
test.OJ<-OJ[-train,]
```
(b) Fit a support vector classifier to the training data using cost=0.01, with Purchase as the response and the other variables as predictors. Use the summary() function to produce summary statistics, and describe the results obtained.
```{r}
library(e1071)
svm.linearOJ<- svm(Purchase ~ ., kernel='linear',  data=train.OJ, cost=0.01)
summary(svm.linearOJ)
```
(c) What are the training and test error rates?
```{r}
train.pred<-predict(svm.linearOJ, train.OJ)
table(train.OJ$Purchase, train.pred)
```
```{r}
mean(train.pred != train.OJ$Purchase)
```

```{r}
test.pred<-predict(svm.linearOJ, test.OJ)
table(test.OJ$Purchase, test.pred)
```

```{r}
mean(test.pred != test.OJ$Purchase)
```
The test error rate is 20.3%

(d) Use the tune() function to select an optimal cost. Consider values in the range 0.01 to 10.
```{r}
tune.OJ<-tune(svm, Purchase ~ ., data=train.OJ, kernel='linear', ranges=list(cost=10^seq(-2,1, by=.5)))
summary(tune.OJ)
```
The most optimal is  cost = 10.

(e) Compute the training and test error rates using this new value for cost.
```{r}
newsvm.linearoj<-svm(Purchase ~ ., kernel='linear', data=train.OJ, cost=tune.OJ$best.parameters$cost)
train.pred<-predict(newsvm.linearoj, train.OJ)
table(train.OJ$Purchase, train.pred)
```

```{r}
mean(train.pred != train.OJ$Purchase)
```
The optimal cost to 15.1%

```{r}
test.pred<-predict(newsvm.linearoj, test.OJ)
table(test.OJ$Purchase, test.pred)
```

```{r}
mean(test.pred != test.OJ$Purchase)
```
The error rate increased, and the optimal cost to 20.3%

(f) Repeat parts (b) through (e) using a support vector machine with a radial kernel. Use the default value for gamma.
```{r}
svm.radialoj<-svm(Purchase~ ., kernel='radial', data=train.OJ )
summary(svm.radialoj)
```

```{r}
train.pred<-predict(svm.radialoj, train.OJ)
table(train.OJ$Purchase, train.pred)
```

```{r}
mean(train.pred != train.OJ$Purchase)
```

```{r}
test.pred<-predict(svm.radialoj, test.OJ)
table(test.OJ$Purchase, test.pred)
```

```{r}
mean(test.pred != test.OJ$Purchase)
```

```{r}
tunerad.OJ<-tune(svm, Purchase ~ ., data=train.OJ, kernel='radial', ranges=list(cost=10^seq(-2,1, by=.5)))
summary(tunerad.OJ)
```

```{r}
newsvm.radialoj<-svm(Purchase ~ ., kernel='radial', data=train.OJ, cost=tunerad.OJ$best.parameters$cost)
train.pred<-predict(newsvm.radialoj, train.OJ)
table(train.OJ$Purchase, train.pred)
```

```{r}
mean(train.pred != train.OJ$Purchase)
```
Optimal cost 14%
```{r}
test.pred<-predict(newsvm.radialoj, test.OJ)
table(test.OJ$Purchase, test.pred)
```

```{r}
mean(test.pred != test.OJ$Purchase)
```
The optimal cost is 20.3%

(g) Repeat parts (b) through (e) using a support vector machine with a polynomial kernel. Set degree=2.
```{r}
svm.polyoj<-svm(Purchase~ ., kernel='polynomial', data=train.OJ, degree=2 )
summary(svm.polyoj)
```

```{r}
train.pred<-predict(svm.polyoj, train.OJ)
table(train.OJ$Purchase, train.pred)
```

```{r}
mean(train.pred != train.OJ$Purchase)
```

```{r}
test.pred<-predict(svm.polyoj, test.OJ)
table(test.OJ$Purchase, test.pred)
```

```{r}
mean(test.pred != test.OJ$Purchase)
```

```{r}
tunepoly.OJ<-tune(svm, Purchase ~ ., data=train.OJ, kernel='polynomial', degree=2, ranges=list(cost=10^seq(-2,1, by=.5)))
summary(tunepoly.OJ)
```

```{r}
newsvm.polyoj<-svm(Purchase ~ ., kernel='polynomial', data=train.OJ, degree=2, cost=tunerad.OJ$best.parameters$cost)
train.pred<-predict(newsvm.polyoj, train.OJ)
table(train.OJ$Purchase, train.pred)
```

```{r}
mean(train.pred != train.OJ$Purchase)
```

```{r}
test.pred<-predict(newsvm.polyoj, test.OJ)
table(test.OJ$Purchase, test.pred)
```

```{r}
mean(test.pred != test.OJ$Purchase)
```
The test error of polynomial kernel with optimal cost is 19.6%



(h) Overall, which approach seems to give the best results on this data?

The way to give the best results on this data is based on the radial kernel and the default gamma. This method has the lowest misclassification rate for both training data set and test data set.